# Neural-Machine-Translation-BERT-CLIP

This repository contains codes for a computer assignment for Neural Networks and Deep Learning course (CSC413/2516, Winter 2022, UofT)

In the first part, we trained neural machine translation model on the toy task of English â†’ Pig Latin. The goal is to build a NMT model that can learn the rules of Pig-Latin implicitly from (English,
Pig-Latin) word pairs. Since the translation to Pig Latin involves moving characters around in a string, we will use character-level recurrent neural networks (RNNs). 
In the second part, we added Attention to the model to improve results.
In the third part, we fine-tuned a pre-trained BERT model for a simple positive/negative classification task.
The codes are in PyTorch.
